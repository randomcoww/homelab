---
networkd:
  units:
    - name: {{.host_if}}.network
      contents: |
        [Match]
        Name={{.host_if}}

        [Network]
        LinkLocalAddressing=no
        DHCP=yes

        [Address]
        Address={{.host_ip}}/{{.host_netmask}}
systemd:
  units:
    - name: containerd.service
      enabled: true
    - name: docker.service
      mask: true
    - name: kubelet.service
      enabled: true
      contents: |
        [Unit]
        Description=Kubelet via Hyperkube ACI

        [Service]
        Environment="KUBELET_IMAGE=docker://{{.hyperkube_image}}"
        Environment="RKT_RUN_ARGS=--uuid-file-save=/var/cache/kubelet-pod.uuid \
          --volume=resolv,kind=host,source=/etc/resolv.conf \
          --volume var-lib-containerd,kind=host,source=/var/lib/containerd,readOnly=false \
          --mount volume=resolv,target=/etc/resolv.conf \
          --mount volume=var-lib-containerd,target=/var/lib/containerd \
          --insecure-options=image"
        ExecStartPre=/bin/mkdir -p /var/log/containers
        ExecStartPre=-/usr/bin/rkt rm --uuid-file=/var/cache/kubelet-pod.uuid
        ExecStart=/usr/lib/coreos/kubelet-wrapper \
          --manifest-url={{.manifest_url}} \
          --container-runtime=remote \
          --container-runtime-endpoint=unix:///run/docker/libcontainerd/docker-containerd.sock
        ExecStop=-/usr/bin/rkt stop --uuid-file=/var/cache/kubelet-pod.uuid
        Restart=on-failure
        RestartSec=5

        [Install]
        WantedBy=multi-user.target
storage:
  files:
    - path: /etc/hostname
      filesystem: root
      mode: 0644
      contents:
        inline:
          {{.hostname}}
    - path: /etc/sysctl.d/max-user-watches.conf
      filesystem: root
      mode: 0644
      contents:
        inline: |
          fs.inotify.max_user_watches=16184

    - path: {{.kubernetes_path}}/ca.pem
      filesystem: root
      mode: 420
      contents:
        inline: "{{.tls_ca}}"
    - path: {{.kubernetes_path}}/ca-key.pem
      filesystem: root
      mode: 420
      contents:
        inline: "{{.tls_ca_key}}"
    - path: {{.kubernetes_path}}/kubernetes.pem
      filesystem: root
      mode: 420
      contents:
        inline: "{{.tls_kubernetes}}"
    - path: {{.kubernetes_path}}/kubernetes-key.pem
      filesystem: root
      mode: 420
      contents:
        inline: "{{.tls_kubernetes_key}}"
    - path: {{.kubernetes_path}}/kube-controller-manager.pem
      filesystem: root
      mode: 420
      contents:
        inline: "{{.tls_controller_manager}}"
    - path: {{.kubernetes_path}}/kube-controller-manager-key.pem
      filesystem: root
      mode: 420
      contents:
        inline: "{{.tls_controller_manager_key}}"
    - path: {{.kubernetes_path}}/kube-scheduler.pem
      filesystem: root
      mode: 420
      contents:
        inline: "{{.tls_scheduler}}"
    - path: {{.kubernetes_path}}/kube-scheduler-key.pem
      filesystem: root
      mode: 420
      contents:
        inline: "{{.tls_scheduler_key}}"
    - path: {{.kubernetes_path}}/service-account.pem
      filesystem: root
      mode: 420
      contents:
        inline: "{{.tls_service_account}}"
    - path: {{.kubernetes_path}}/service-account-key.pem
      filesystem: root
      mode: 420
      contents:
        inline: "{{.tls_service_account_key}}"

    - path: {{.kubernetes_path}}/kube-scheduler.yaml
      filesystem: root
      mode: 420
      contents:
        inline: |-
          apiVersion: componentconfig/v1alpha1
          kind: KubeSchedulerConfiguration
          clientConnection:
            kubeconfig: "{{.kubernetes_path}}/kube-scheduler.kubeconfig"
          leaderElection:
            leaderElect: true

    - path: {{.kubernetes_path}}/kube-controller-manager.kubeconfig
      filesystem: root
      mode: 420
      contents:
        inline: |-
          apiVersion: v1
          clusters:
          - cluster:
              certificate-authority: {{.kubernetes_path}}/ca.pem
              server: {{.apiserver_url}}
            name: {{.cluster_name}}
          contexts:
          - context:
              cluster: {{.cluster_name}}
              user: system:kube-controller-manager
            name: default
          current-context: default
          kind: Config
          preferences: {}
          users:
          - name: system:kube-controller-manager
            user:
              client-certificate: {{.kubernetes_path}}/kube-controller-manager.pem
              client-key: {{.kubernetes_path}}/kube-controller-manager-key.pem

    - path: {{.kubernetes_path}}/kube-scheduler.kubeconfig
      filesystem: root
      mode: 420
      contents:
        inline: |-
          apiVersion: v1
          clusters:
          - cluster:
              certificate-authority: {{.kubernetes_path}}/ca.pem
              server: {{.apiserver_url}}
            name: {{.cluster_name}}
          contexts:
          - context:
              cluster: {{.cluster_name}}
              user: system:kube-scheduler
            name: default
          current-context: default
          kind: Config
          preferences: {}
          users:
          - name: system:kube-scheduler
            user:
              client-certificate: {{.kubernetes_path}}/kube-scheduler.pem
              client-key: {{.kubernetes_path}}/kube-scheduler-key.pem
    - path: /etc/cni/net.d/99-loopback.conf
      filesystem: root
      mode: 420
      contents:
        inline: |-
          {
            "cniVersion": "0.3.1",
            "type": "loopback"
          }
passwd:
  users:
  - name: {{.default_user}}
    ssh_authorized_keys:
      - {{.ssh_authorized_key}}
